{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "np.random.seed(11) \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_benign_train = 'dataset/data/train/benign'\n",
    "folder_malignant_train = 'dataset/data/train/malignant'\n",
    "\n",
    "folder_benign_test = 'dataset/data/test/benign'\n",
    "folder_malignant_test = 'dataset/data/test/malignant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
    "\n",
    "# Load in training pictures\n",
    "ims_benign = [read(os.path.join(folder_benign_train, filename)) for filename in os.listdir(folder_benign_train)]\n",
    "X_benign = np.array(ims_benign, dtype='uint8')\n",
    "ims_malignant = [read(os.path.join(folder_malignant_train, filename)) for filename in os.listdir(folder_malignant_train)]\n",
    "X_malignant = np.array(ims_malignant, dtype='uint8')\n",
    "\n",
    "# Load in testing pictures\n",
    "ims_benign = [read(os.path.join(folder_benign_test, filename)) for filename in os.listdir(folder_benign_test)]\n",
    "X_benign_test = np.array(ims_benign, dtype='uint8')\n",
    "ims_malignant = [read(os.path.join(folder_malignant_test, filename)) for filename in os.listdir(folder_malignant_test)]\n",
    "X_malignant_test = np.array(ims_malignant, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "y_benign = np.zeros(X_benign.shape[0])\n",
    "y_malignant = np.ones(X_malignant.shape[0])\n",
    "\n",
    "y_benign_test = np.zeros(X_benign_test.shape[0])\n",
    "y_malignant_test = np.ones(X_malignant_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "X_train = np.concatenate((X_benign, X_malignant), axis = 0)\n",
    "y_train = np.concatenate((y_benign, y_malignant), axis = 0)\n",
    "\n",
    "X_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\n",
    "y_test = np.concatenate((y_benign_test, y_malignant_test), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "s = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_train = X_train[s]\n",
    "y_train = y_train[s]\n",
    "\n",
    "s = np.arange(X_test.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_test = X_test[s]\n",
    "y_test = y_test[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 15 images of moles, and how they are classified\n",
    "w=40\n",
    "h=30\n",
    "fig=plt.figure(figsize=(12, 8))\n",
    "columns = 5\n",
    "rows = 3\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    ax = fig.add_subplot(rows, columns, i)\n",
    "    if y_train[i] == 0:\n",
    "        ax.title.set_text('Benign')\n",
    "    else:\n",
    "        ax.title.set_text('Malignant')\n",
    "    plt.imshow(X_train[i], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir etiquetas a cetegóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes= 2)\n",
    "y_test = to_categorical(y_test, num_classes= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.\n",
    "X_test = X_test/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)  # Actualiza este valor según el tamaño real de tus imágenes\n",
    "\n",
    "# Creando el modelo de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))  # Una capa de max pooling adicional para manejar el aumento de tamaño de la imagen\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))  # Capa adicional para más complejidad\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))  # Aumentamos el tamaño aquí para ajustar al tamaño aumentado de las imágenes\n",
    "model.add(layers.Dense(2, activation='sigmoid'))  # Dos clases de salida: benigno (0) y maligno (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Cambio en la función de pérdida para clasificación binaria\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs= 25,\n",
    "                    batch_size=64,\n",
    "                    verbose=1,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar modelo\n",
    "if not os.path.exists('/content/drive/MyDrive/Datos no estructurados/Skin/models'):\n",
    "    print('No existe la carpeta')\n",
    "    os.mkdir('/content/drive/MyDrive/Datos no estructurados/Skin/models')\n",
    "\n",
    "model.save('/content/drive/MyDrive/Datos no estructurados/Skin/models/cnn_scratch-25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('/content/drive/MyDrive/Datos no estructurados/Skin/images/acc-25.png')\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('/content/drive/MyDrive/Datos no estructurados/Skin/images/loss-25.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('/content/drive/MyDrive/Datos no estructurados/Skin/images/acc-25.png')\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('/content/drive/MyDrive/Datos no estructurados/Skin/images/loss-25.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
